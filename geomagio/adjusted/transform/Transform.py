import numpy as np
from obspy import UTCDateTime
from pydantic import BaseModel
from typing import List, Optional, Tuple

from ...residual.Reading import Reading, get_baselines, get_times


class Transform(BaseModel):
    """Method for generating an affine matrix.

    Attributes
    ----------
    acausal: if true, future readings are used in calculations
    memory: Controls impact of measurements from the past
    Defaults to infinite(equal weighting)
    """

    acausal: bool = False
    memory: Optional[float] = None
    ndims: int = 3

    def calculate(
        self,
        ordinates: Tuple[List[float], List[float], List[float]],
        absolutes: Tuple[List[float], List[float], List[float]],
        weights: List[float],
    ) -> np.array:
        """Type skeleton inherited by any instance of Transform

        Attributes
        ----------
        ordinates: H, E and Z ordinates
        absolutes: X, Y and Z absolutes(NOTE: absolutes must be rotated from original H, E and Z values)
        weights: time weights to apply during calculations of matrices
        """
        return

    def get_weights(self, readings: List[Reading], time: int = None) -> List[float]:
        """
        Calculate time-dependent weights according to exponential decay.

        Inputs:
        times: array of times, or any time-like index whose relative values represent spacing between events
        Output:
        weights: array of vector distances/metrics
        """

        times = get_times(readings)
        # convert to array of floats
        times = np.asarray(times).astype(float)

        if time is None:
            time = float(max(times))

        baselines = get_baselines(readings)

        # if memory is actually infinite, return equal weights
        if np.isinf(self.memory):
            return filter_iqrs(multiseries=baselines, weights=np.ones(times.shape))

        # initialize weights
        weights = np.zeros(times.shape)

        # calculate exponential decay time-dependent weights
        weights[times <= time] = np.exp((times[times <= time] - time) / self.memory)
        weights[times >= time] = np.exp((time - times[times >= time]) / self.memory)

        if not self.acausal:
            weights[times > time] = 0.0

        weights = filter_iqrs(multiseries=baselines, weights=weights)

        return weights


def filter_iqr(
    series: List[float], threshold: int = 3.0, weights: List[int] = None
) -> List[int]:
    """
    Identify "good" elements in series by calculating potentially weighted
    25%, 50% (median), and 75% quantiles of series, the number of 25%-50%
    quantile ranges below, or 50%-75% quantile ranges above each value of
    series falls from the median, and finally, setting elements of good to
    True that fall within these multiples of quantile ranges.

    NOTE: NumPy has a percentile function, but it does not yet handle
          weights. This algorithm was adapted from the PyPI
          package wquantiles (https://pypi.org/project/wquantiles/)

    Inputs:
    series: array of observations to filter

    Options:
    threshold: threshold in fractional number of 25%-50% (50%-75%)
                quantile ranges below (above) the median each element of
                series may fall and still be considered "good"
                Default set to 6.
    weights: weights to assign to each element of series. Default set to 1.

    Output:
    good: Boolean array where True values correspond to "good" data

    """

    if weights is None:
        weights = np.ones_like(series)

    # initialize good as all True for weights greater than 0
    good = (weights > 0).astype(bool)
    if np.size(good) <= 1:
        # if a singleton is passed, assume it is "good"
        return good

    good_old = ~good
    while not (good_old == good).all():
        good_old = good

        wq25 = weighted_quartile(series[good], weights[good], 0.25)
        wq50 = weighted_quartile(series[good], weights[good], 0.50)
        wq75 = weighted_quartile(series[good], weights[good], 0.75)

        # NOTE: it is necessary to include good on the RHS here
        #       to prevent oscillation between two equally likely
        #       "optimal" solutions; this is a common problem with
        #       expectation maximization algorithms
        good = (
            good
            & (series >= (wq50 - threshold * (wq50 - wq25)))
            & (series <= (wq50 + threshold * (wq75 - wq50)))
        )

    return good


def filter_iqrs(
    multiseries: List[List[float]],
    weights: List[float],
    threshold: float = 3.0,
) -> List[float]:
    """Filters "bad" weights generated by unreliable readings"""
    good = None
    for series in multiseries:
        filtered = filter_iqr(series, threshold=threshold, weights=weights)
        if good is None:
            good = filtered
        else:
            good = good & filtered

    return weights * good


def weighted_quartile(data: List[float], weights: List[float], quant: float) -> float:
    """Get weighted quartile to determine statistically good/bad data

    Attributes
    ----------
    data: filtered array of observations
    weights: array of vector distances/metrics
    quant: statistical percentile of input data
    """
    # sort data and weights
    ind_sorted = np.argsort(data)
    sorted_data = data[ind_sorted]
    sorted_weights = weights[ind_sorted]
    # compute auxiliary arrays
    Sn = np.cumsum(sorted_weights)
    Pn = (Sn - 0.5 * sorted_weights) / Sn[-1]
    # interpolate to weighted quantile
    return np.interp(quant, Pn, sorted_data)
